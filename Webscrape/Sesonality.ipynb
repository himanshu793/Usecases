{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moving Average Approach:\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with quarterly data\n",
    "data = {\n",
    "    'Quarter': ['Q1', 'Q2', 'Q3', 'Q4', 'Q1', 'Q2', 'Q3', 'Q4'],\n",
    "    'Value': [100, 110, 120, 130, 140, 150, 160, 170]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate average value for each quarter\n",
    "quarterly_avg = df.groupby('Quarter')['Value'].mean()\n",
    "\n",
    "# Calculate the overall average\n",
    "overall_avg = df['Value'].mean()\n",
    "\n",
    "# Calculate the seasonality index\n",
    "seasonality_index = quarterly_avg / overall_avg\n",
    "\n",
    "print(seasonality_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decomposition approach\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Create a DataFrame with quarterly data\n",
    "data = {\n",
    "    'Quarter': ['Q1', 'Q2', 'Q3', 'Q4', 'Q1', 'Q2', 'Q3', 'Q4'],\n",
    "    'Value': [100, 110, 120, 130, 140, 150, 160, 170]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the DataFrame to a time series\n",
    "df['Quarter'] = pd.to_datetime(df['Quarter'], format='Q%m').dt.to_period('Q')\n",
    "df.set_index('Quarter', inplace=True)\n",
    "\n",
    "# Perform seasonal decomposition\n",
    "decomposition = seasonal_decompose(df['Value'], model='additive',period=4)\n",
    "\n",
    "# Extract the seasonal component\n",
    "seasonal_component = decomposition.seasonal\n",
    "\n",
    "# Calculate the average seasonal component for each quarter\n",
    "quarterly_avg_seasonality = seasonal_component.groupby(seasonal_component.index.quarter).mean()\n",
    "\n",
    "# Calculate the overall average\n",
    "overall_avg = df['Value'].mean()\n",
    "\n",
    "# Calculate the seasonality index\n",
    "seasonality_index = quarterly_avg_seasonality / overall_avg\n",
    "\n",
    "print(seasonality_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.28054D+02    |proj g|=  5.99081D+02\n",
      "\n",
      "At iterate    5    f=  3.46716D+01    |proj g|=  1.24812D+01\n",
      "\n",
      "At iterate   10    f=  8.28781D+00    |proj g|=  6.08114D-01\n",
      "\n",
      "At iterate   15    f=  5.82571D+00    |proj g|=  2.38970D-02\n",
      "\n",
      "At iterate   20    f=  5.71782D+00    |proj g|=  7.42283D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     22     24      1     0     0   5.959D-06   5.718D+00\n",
      "  F =   5.7177244756732044     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "Quarter\n",
      "1    0.780052\n",
      "2    0.921880\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/himanshu/.local/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/himanshu/.local/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/himanshu/.local/lib/python3.8/site-packages/statsmodels/tsa/statespace/sarimax.py:997: UserWarning: Non-stationary starting seasonal autoregressive Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting seasonal autoregressive'\n",
      " This problem is unconstrained.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Create a DataFrame with quarterly data\n",
    "data = {\n",
    "    'Quarter': ['Q1', 'Q2', 'Q3', 'Q4', 'Q1', 'Q2', 'Q3', 'Q4'],\n",
    "    'Value': [100, 110, 120, 130, 140, 150, 160, 170]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the DataFrame to a time series\n",
    "df['Quarter'] = pd.to_datetime(df['Quarter'], format='Q%m').dt.to_period('Q')\n",
    "df.set_index('Quarter', inplace=True)\n",
    "\n",
    "# Fit SARIMA model\n",
    "model = SARIMAX(df['Value'], order=(0, 0, 0), seasonal_order=(1, 0, 0, 4))\n",
    "results = model.fit()\n",
    "\n",
    "# Extract the seasonal component from the fitted values\n",
    "seasonal_component = results.fittedvalues.diff(periods=4)\n",
    "\n",
    "# Calculate the average seasonal component for each quarter\n",
    "quarterly_avg_seasonality = seasonal_component.groupby(seasonal_component.index.quarter).mean()\n",
    "\n",
    "# Calculate the overall average\n",
    "overall_avg = df['Value'].mean()\n",
    "\n",
    "# Calculate the seasonality index\n",
    "seasonality_index = quarterly_avg_seasonality / overall_avg\n",
    "\n",
    "print(seasonality_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m quarter_dummies[\u001b[39m'\u001b[39m\u001b[39mIntercept\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[39m# Fit a regression model\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m model \u001b[39m=\u001b[39m sm\u001b[39m.\u001b[39;49mOLS(df[\u001b[39m'\u001b[39;49m\u001b[39mValue\u001b[39;49m\u001b[39m'\u001b[39;49m], quarter_dummies)\n\u001b[1;32m     26\u001b[0m results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit()\n\u001b[1;32m     28\u001b[0m \u001b[39m# Extract the coefficients from the regression results\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/statsmodels/regression/linear_model.py:922\u001b[0m, in \u001b[0;36mOLS.__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    919\u001b[0m     msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mWeights are not supported in OLS and will be ignored\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    920\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mAn exception will be raised in the next version.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    921\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(msg, ValueWarning)\n\u001b[0;32m--> 922\u001b[0m \u001b[39msuper\u001b[39;49m(OLS, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(endog, exog, missing\u001b[39m=\u001b[39;49mmissing,\n\u001b[1;32m    923\u001b[0m                           hasconst\u001b[39m=\u001b[39;49mhasconst, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    924\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_keys:\n\u001b[1;32m    925\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_keys\u001b[39m.\u001b[39mremove(\u001b[39m\"\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/statsmodels/regression/linear_model.py:748\u001b[0m, in \u001b[0;36mWLS.__init__\u001b[0;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     weights \u001b[39m=\u001b[39m weights\u001b[39m.\u001b[39msqueeze()\n\u001b[0;32m--> 748\u001b[0m \u001b[39msuper\u001b[39;49m(WLS, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(endog, exog, missing\u001b[39m=\u001b[39;49mmissing,\n\u001b[1;32m    749\u001b[0m                           weights\u001b[39m=\u001b[39;49mweights, hasconst\u001b[39m=\u001b[39;49mhasconst, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    750\u001b[0m nobs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    751\u001b[0m weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/statsmodels/regression/linear_model.py:202\u001b[0m, in \u001b[0;36mRegressionModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, endog, exog, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 202\u001b[0m     \u001b[39msuper\u001b[39;49m(RegressionModel, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(endog, exog, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpinv_wexog: Float64Array \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_attr\u001b[39m.\u001b[39mextend([\u001b[39m'\u001b[39m\u001b[39mpinv_wexog\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwendog\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwexog\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/statsmodels/base/model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, endog, exog\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 270\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(endog, exog, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    271\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialize()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/statsmodels/base/model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m missing \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mmissing\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     94\u001b[0m hasconst \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mhasconst\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m---> 95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_data(endog, exog, missing, hasconst,\n\u001b[1;32m     96\u001b[0m                               \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_constant \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mk_constant\n\u001b[1;32m     98\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mexog\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/statsmodels/base/model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_handle_data\u001b[39m(\u001b[39mself\u001b[39m, endog, exog, missing, hasconst, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 135\u001b[0m     data \u001b[39m=\u001b[39m handle_data(endog, exog, missing, hasconst, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    136\u001b[0m     \u001b[39m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m kwargs:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/statsmodels/base/data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[0;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m     exog \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(exog)\n\u001b[1;32m    674\u001b[0m klass \u001b[39m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[0;32m--> 675\u001b[0m \u001b[39mreturn\u001b[39;00m klass(endog, exog\u001b[39m=\u001b[39;49mexog, missing\u001b[39m=\u001b[39;49mmissing, hasconst\u001b[39m=\u001b[39;49mhasconst,\n\u001b[1;32m    676\u001b[0m              \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/statsmodels/base/data.py:84\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morig_endog \u001b[39m=\u001b[39m endog\n\u001b[1;32m     83\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morig_exog \u001b[39m=\u001b[39m exog\n\u001b[0;32m---> 84\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendog, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_endog_exog(endog, exog)\n\u001b[1;32m     86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconst_idx \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_constant \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/statsmodels/base/data.py:509\u001b[0m, in \u001b[0;36mPandasData._convert_endog_exog\u001b[0;34m(self, endog, exog)\u001b[0m\n\u001b[1;32m    507\u001b[0m exog \u001b[39m=\u001b[39m exog \u001b[39mif\u001b[39;00m exog \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m np\u001b[39m.\u001b[39masarray(exog)\n\u001b[1;32m    508\u001b[0m \u001b[39mif\u001b[39;00m endog\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m \u001b[39mor\u001b[39;00m exog \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m exog\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[0;32m--> 509\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPandas data cast to numpy dtype of object. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    510\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mCheck input data with np.asarray(data).\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    511\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(PandasData, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m_convert_endog_exog(endog, exog)\n",
      "\u001b[0;31mValueError\u001b[0m: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data)."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Create a DataFrame with quarterly data\n",
    "data = {\n",
    "    'Quarter': ['2021-03-31', '2021-06-30', '2021-09-30', '2021-12-31', '2022-03-31', '2022-06-30', '2022-09-30', '2022-12-31'],\n",
    "    'Value': [100, 110, 120, 130, 140, 150, 160, 170]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the quarters to datetime objects\n",
    "df['Quarter'] = pd.to_datetime(df['Quarter'], format='%Y-%m-%d')\n",
    "\n",
    "# Convert the quarters to numeric values\n",
    "df['Quarter_Num'] = df['Quarter'].dt.quarter.astype(int)\n",
    "\n",
    "# Create dummy variables for each quarter\n",
    "quarter_dummies = pd.get_dummies(df['Quarter_Num'])\n",
    "\n",
    "# Add an intercept column\n",
    "quarter_dummies['Intercept'] = 1\n",
    "\n",
    "# Fit a regression model\n",
    "model = sm.OLS(df['Value'], quarter_dummies)\n",
    "results = model.fit()\n",
    "\n",
    "# Extract the coefficients from the regression results\n",
    "coefficients = results.params\n",
    "\n",
    "# Calculate the seasonality index\n",
    "seasonality_index = coefficients[1:-1] / coefficients[-1]\n",
    "\n",
    "# Print the seasonality index\n",
    "print(seasonality_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarter_Num\n",
      "1    135.0\n",
      "2    135.0\n",
      "Name: Value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a DataFrame with quarterly data\n",
    "data = {\n",
    "    'Quarter': ['Q1', 'Q2', 'Q3', 'Q4', 'Q1', 'Q2', 'Q3', 'Q4'],\n",
    "    'Value': [100, 110, 120, 130, 140, 150, 160, 170]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the quarters to numeric values\n",
    "df['Quarter_Num'] = pd.to_datetime(df['Quarter'], format='Q%m').dt.quarter\n",
    "\n",
    "# Calculate the average value for each quarter\n",
    "quarterly_avg = df.groupby('Quarter_Num')['Value'].mean()\n",
    "\n",
    "# Calculate the overall average\n",
    "overall_avg = df['Value'].mean()\n",
    "\n",
    "# Calculate the detrended values\n",
    "detrended_values = df['Value'] / quarterly_avg[df['Quarter_Num']].values * overall_avg\n",
    "\n",
    "# Calculate the seasonality index\n",
    "seasonality_index = detrended_values.groupby(df['Quarter_Num']).mean()\n",
    "\n",
    "print(seasonality_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarter_Num\n",
      "1900Q1    0.0\n",
      "Freq: Q-DEC, Name: seasonal, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Create a DataFrame with quarterly data\n",
    "data = {\n",
    "    'Quarter': ['Q1', 'Q2', 'Q3', 'Q4', 'Q1', 'Q2', 'Q3', 'Q4'],\n",
    "    'Value': [100, 110, 120, 130, 140, 150, 160, 170]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the quarters to numeric values\n",
    "df['Quarter_Num'] = pd.to_datetime(df['Quarter'], format='Q%m').dt.quarter\n",
    "\n",
    "# Convert the DataFrame to a time series\n",
    "df['Quarter_Num'] = pd.to_datetime(df['Quarter_Num'], format='%m').dt.to_period('Q')\n",
    "df.set_index('Quarter_Num', inplace=True)\n",
    "\n",
    "# Perform seasonal decomposition\n",
    "decomposition = seasonal_decompose(df['Value'], model='additive',period=4)\n",
    "\n",
    "# Extract the seasonal component\n",
    "seasonal_component = decomposition.seasonal\n",
    "\n",
    "# Calculate the average seasonal component for each quarter\n",
    "quarterly_avg_seasonality = seasonal_component.groupby(seasonal_component.index).mean()\n",
    "\n",
    "# Calculate the overall average\n",
    "overall_avg = df['Value'].mean()\n",
    "\n",
    "# Calculate the seasonality index\n",
    "seasonality_index = quarterly_avg_seasonality / overall_avg\n",
    "\n",
    "print(seasonality_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.fft import fft, ifft\n",
    "\n",
    "# Create a DataFrame with quarterly data\n",
    "data = {\n",
    "    'Quarter': ['Q1', 'Q2', 'Q3', 'Q4', 'Q1', 'Q2', 'Q3', 'Q4'],\n",
    "    'Value': [100, 110, 120, 130, 140, 150, 160, 170]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the quarters to numeric values\n",
    "df['Quarter_Num'] = pd.to_datetime(df['Quarter'], format='Q%m').dt.quarter\n",
    "\n",
    "# Create a periodic signal based on the quarterly values\n",
    "signal = np.tile(df['Value'], int(np.ceil(df.shape[0] / 4)))[:df.shape[0]]\n",
    "\n",
    "# Apply Fourier transformation\n",
    "fourier = fft(signal)\n",
    "\n",
    "# Identify the indices corresponding to the quarterly frequencies\n",
    "quarter_freq_indices = np.arange(1, df.shape[0] + 1)\n",
    "\n",
    "# Calculate the magnitudes of the quarterly frequencies\n",
    "magnitudes = np.abs(fourier[quarter_freq_indices]) / df.shape[0]\n",
    "\n",
    "# Calculate the average magnitude for each quarter\n",
    "quarterly_avg_magnitudes = magnitudes.mean()\n",
    "\n",
    "# Calculate the overall average\n",
    "overall_avg = df['Value'].mean()\n",
    "\n",
    "# Calculate the seasonality index\n",
    "seasonality_index = quarterly_avg_magnitudes / overall_avg\n",
    "\n",
    "print(seasonality_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.75299969e+15  3.75299969e+15]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This linear regression approach estimates the seasonality index by modeling the relationship \n",
    "between the quarters (represented as one-hot encoded variables) and the values. It captures \n",
    "the relative contribution of each quarter to the overall pattern.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a DataFrame with quarterly data\n",
    "data = {\n",
    "    'Quarter': ['Q1', 'Q2', 'Q3', 'Q4', 'Q1', 'Q2', 'Q3', 'Q4'],\n",
    "    'Value': [100, 110, 120, 130, 140, 150, 160, 170]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the quarters to numeric values\n",
    "df['Quarter_Num'] = pd.to_datetime(df['Quarter'], format='Q%m').dt.quarter\n",
    "\n",
    "# Create a one-hot encoding for the quarters\n",
    "quarter_dummies = pd.get_dummies(df['Quarter_Num'], prefix='Q')\n",
    "\n",
    "# Fit a linear regression model\n",
    "regression_model = LinearRegression()\n",
    "regression_model.fit(quarter_dummies, df['Value'])\n",
    "\n",
    "# Extract the coefficients from the regression model\n",
    "coefficients = regression_model.coef_\n",
    "\n",
    "# Calculate the seasonality index\n",
    "seasonality_index = coefficients / np.mean(coefficients)\n",
    "\n",
    "print(seasonality_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarter\n",
      "1   -0.025186\n",
      "2    0.004445\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/himanshu/.local/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/himanshu/.local/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The Holt-Winters exponential smoothing method is specifically designed to capture seasonality in time series data. \n",
    "It models and estimates the seasonal component, allowing for a robust estimation of the seasonality index at the quarter level.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Create a DataFrame with quarterly data\n",
    "data = {\n",
    "    'Quarter': ['Q1', 'Q2', 'Q3', 'Q4', 'Q1', 'Q2', 'Q3', 'Q4'],\n",
    "    'Value': [100, 110, 120, 130, 140, 150, 160, 170]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the quarters to datetime format\n",
    "df['Quarter'] = pd.to_datetime(df['Quarter'], format='Q%m')\n",
    "\n",
    "# Convert the DataFrame to a time series\n",
    "df.set_index('Quarter', inplace=True)\n",
    "\n",
    "# Apply Holt-Winters exponential smoothing with additive seasonality\n",
    "model = ExponentialSmoothing(df['Value'], seasonal='add', seasonal_periods=4)\n",
    "results = model.fit()\n",
    "\n",
    "# Extract the seasonal component from the fitted model\n",
    "seasonal_component = results.season\n",
    "\n",
    "# Calculate the average seasonal component for each quarter\n",
    "quarterly_avg_seasonality = seasonal_component.groupby(seasonal_component.index.quarter).mean()\n",
    "\n",
    "# Calculate the overall average\n",
    "overall_avg = df['Value'].mean()\n",
    "\n",
    "# Calculate the seasonality index\n",
    "seasonality_index = quarterly_avg_seasonality / overall_avg\n",
    "\n",
    "print(seasonality_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
